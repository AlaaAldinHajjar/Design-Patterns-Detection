{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94161bd",
   "metadata": {},
   "source": [
    "#  Design Patterns Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c2c569",
   "metadata": {},
   "source": [
    "## importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6e6e3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import DBSCAN,KMeans\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d41e94",
   "metadata": {},
   "source": [
    "## creating a list for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aa669ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "creational=['Abstract_factory','Builder','Factory','Prototype','Singleton']\n",
    "structural=['Adapter','Bridge','Composite','Decorator','Facade','Flyweight','Proxy']\n",
    "behavioral=['Chain_of_responsibility','Command','Interpreter','Iterator','Mediator','Memento','Observer','State','Strategy','Template','Visitor']\n",
    "df_dir = 'Dp_trainset'\n",
    "test_df_dir ='Dp_testset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10925760",
   "metadata": {},
   "source": [
    "## imput function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e194e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imput(df):\n",
    "    for c in df:\n",
    "        df[c].fillna((df[c].mean()), inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b48001",
   "metadata": {},
   "source": [
    "## preprocessing function that reads class file and do input for it after skipping the first three columns, because the most useful one is class file and represent it as a row in our data set by do sum on axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97539505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(df_dir):\n",
    "    X,y=[],[]\n",
    "    empty=0\n",
    "    for foldername in os.listdir(df_dir):\n",
    "        lable='n'\n",
    "        if foldername in creational:\n",
    "            lable=0\n",
    "        elif foldername in structural:\n",
    "            lable=1\n",
    "        elif foldername in behavioral:\n",
    "            lable=2\n",
    "        for folder in os.listdir(df_dir+'/'+foldername):\n",
    "            row=[]\n",
    "            df_class = pd.read_csv(df_dir+'/'+foldername+'/'+folder+'/ckmetrics/class.csv')\n",
    "            if len(df_class)==0:\n",
    "                empty+=1\n",
    "                continue\n",
    "            class_count=(df_class.type=='class').sum()\n",
    "            inter_count=(df_class.type=='interface').sum()\n",
    "            df_class=df_class.iloc[:,3:]\n",
    "            df_class=imput(df_class)\n",
    "            row=np.append(row,df_class.sum(axis=0))\n",
    "            row=np.append(row,class_count)\n",
    "            row=np.append(row,inter_count)\n",
    "            X.append(row)\n",
    "            y.append(lable)\n",
    "    return pd.DataFrame(X),pd.DataFrame(y),empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae7c7b7",
   "metadata": {},
   "source": [
    "## preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b7e9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,e=prepro(df_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "990eb2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test,e=prepro(test_df_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b566917e",
   "metadata": {},
   "source": [
    "## i didn't do scale for the data because i am using trees "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2276ac27",
   "metadata": {},
   "source": [
    "## explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "77056266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 246, 1: 54, 2: 69}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0233f20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 38, 1: 35, 2: 40}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique2, counts2 = np.unique(y_test, return_counts=True)\n",
    "dict(zip(unique2, counts2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0635e2f2",
   "metadata": {},
   "source": [
    "## using random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "455ce036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set is:\n",
      "\n",
      "{'max_features': 'auto', 'min_impurity_decrease': 0, 'n_estimators': 44}\n",
      "0.46017699115044247\n"
     ]
    }
   ],
   "source": [
    "params = {'min_impurity_decrease':[0, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "              'max_features':['auto', 'sqrt', 'log2'],\n",
    "              'n_estimators':list(range(1, 50))}\n",
    "\n",
    "gsr = GridSearchCV(estimator=RandomForestClassifier(),cv=2,param_grid=params)\n",
    "\n",
    "gsr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(\"Best parameters set is:\\n\")\n",
    "print(gsr.best_params_)\n",
    "\n",
    "y_predr = gsr.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8c07572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "153902ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0790b4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 2,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 1, 0, 2, 0,\n",
       "       0, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "821b4dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45132743362831856"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " accuracy_score(rf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4a0862eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997289972899729"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " accuracy_score(rf.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9552c418",
   "metadata": {},
   "source": [
    "## we can see a lot of overfitting :( let us try grid search on other models we will use DecisionTreeClassifier and LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "884773fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set is:\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 5}\n",
      "0.504424778761062\n"
     ]
    }
   ],
   "source": [
    "tree_params = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "gs = GridSearchCV(DecisionTreeClassifier(), tree_params, cv=2)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Best parameters set is:\\n\")\n",
    "print(gs.best_params_)\n",
    "\n",
    "y_pred = gs.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7911e84c",
   "metadata": {},
   "source": [
    "still not that good, hmmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1893e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.57195946        nan 0.5854436         nan 0.58519389\n",
      "        nan 0.57978848        nan 0.60141011        nan 0.5987074\n",
      "        nan 0.59601939        nan 0.60956228        nan 0.61769976\n",
      "        nan 0.61769976]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set is:\n",
      "\n",
      "{'max_iter': 800, 'penalty': 'l2'}\n",
      "0.6106194690265486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\AI\\envs\\gpupy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "params =  {'penalty':['l1', 'l2', 'elasticnet', 'none'],'max_iter':[50,100,200,400,800]}\n",
    "\n",
    "gs1 = GridSearchCV(LogisticRegression(), params, cv=2)\n",
    "gs1.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(\"Best parameters set is:\\n\")\n",
    "print(gs1.best_params_)\n",
    "\n",
    "y_pred1 = gs1.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce3cab",
   "metadata": {},
   "source": [
    "## so we can see that the first place goes to logistic Regression with Grid Search with the result:\n",
    "\n",
    "\n",
    "Best parameters set is:\n",
    "\n",
    "{'max_iter': 800, 'penalty': 'l2'}\n",
    "\n",
    "\n",
    "0.6106194690265486"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
